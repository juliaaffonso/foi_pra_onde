name: Run Scraper

on:
  schedule:
    - cron: '7 7 * * *'  # 4:07 a.m. Bras√≠lia time (BRT = UTC-3)
  workflow_dispatch:     # manual trigger

jobs:
  scrape:
    runs-on: ubuntu-latest
    
    permissions:
      contents: write

    steps:
    - name: Checkout repo
      uses: actions/checkout@v3
      # Note: persist-credentials is true by default, but it's good to be explicit.
      # This step configures git to use the GITHUB_TOKEN automatically for push.
      with:
        persist-credentials: true

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'

    - name: Install dependencies
      run: pip install -r scraper/requirements.txt

    - name: Run scraper
      run: python scraper/scraper.py

    # This step can now be simplified
    - name: Commit and push scraped data
      run: |
        git config --global user.name "github-actions[bot]"
        git config --global user.email "github-actions[bot]@users.noreply.github.com"
        # Check if there are any changes to commit
        if [ -n "$(git status --porcelain)" ]; then
          git add docs/data/all_data.json
          git commit -m "Update scraped data"
          git push
        else
          echo "No changes to commit."
        fi